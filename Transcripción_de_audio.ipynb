{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNu32Gp2dy11EWGvLpZqrFe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Starleen1996/Curso-IA-Generativa/blob/main/Transcripci%C3%B3n_de_audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tgEaB0lPxSrO",
        "outputId": "7fad93af-f3af-4424-eabd-8f51107b92e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton>=2->openai-whisper) (75.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.11.1.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=5a0720d104185de48f4679f17a5902626d823916afe8118d05e2614d3b98a994\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/d2/20/09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: openai-whisper\n",
            "Successfully installed openai-whisper-20250625\n"
          ]
        }
      ],
      "source": [
        "!pip install openai-whisper\n",
        "import whisper"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"small\")\n",
        "result=model.transcribe(\"/content/Desafíos y soluciones del trabajo remoto #AluraTips.mp3\") # carga el archivo antes\n",
        "print(result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVK7mlIxyPC2",
        "outputId": "6f340bfe-5480-41cc-eb38-534262751db4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:05<00:00, 89.4MiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " El trabajo remoto se ha vuelto una realidad últimamente para muchos de los trabajadores. Y entonces, en este video, vamos a hablar sobre los desafíos y las soluciones que las personas pueden encontrar con este modelo de trabajo. Les doy la bienvenida una vez más al canal de Alura Latam. El día de hoy estamos con Raquel Coimbra, aquí de nuestro equipo Latam, con quien vamos a estar platicando sobre algunos desafíos y soluciones del trabajo remoto. Entonces, Raquel, ya para entrar en el tema, ¿cuáles son los desafíos que tanto los colaboradores como las empresas pueden encontrar con este modelo de trabajo? Hola Gabi, claro que sí. Bueno, el trabajo remoto tiene muchas ventajas, pero también tiene sus desventajas. Entonces, uno de los problemas que yo veo es la falta de comunicación efectiva. También está la cuestión de la productividad. También vemos el equilibrio o la falta de equilibrio entre la vida personal y la vida profesional. Sí, esos puntos son muy importantes, ¿no? Y vemos con la comunicación que es algo crucial, tanto para la vida personal, pero es muy importante en el trabajo, para las empresas, porque trabajamos como chés personas, no el trabajo en equipo. Entonces, puedes comentarnos qué pueden hacer las empresas que medidas pueden tomar para ayudar con esta falta de comunicación. Claro, muchas empresas utilizan herramientas de mensajería, como por ejemplo Discord o Slack. También utilizan herramientas de video como Zoom o como Microsoft Teams. Y también fortalecen la cultura de la empresa. Y esos son estrategias que ayudan bastante a tener un buen trabajo remoto. No, así es, porque la comunicación clara y transparente es un punto muy importante en el momento de tener trabajo remoto, ¿no? Pero cuando estamos trabajando con otras personas, estamos trabajando en equipo, necesitamos tener una comunicación muy bien y muy efectiva. Y hablando también de la productividad, ¿no? Entonces, ¿cómo pueden los colaboradores hacerse más productivos trabajando desde casa? Hay algunas estrategias que podemos utilizar. Entonces, por ejemplo, está la técnica Pomodoro, que es básicamente estar un tiempo trabajando y darse unos minutos de descanso. Y claro, tener una rutina. Eso es lo primero y lo básico, establecer una rutina. Y también es muy importante tener un trabajo fijo donde uno sabe que ahí va a ser su lugar de trabajo. Así es. Sí, porque si pensamos, ¿no? El trabajo ahora con el trabajo remoto, entró dentro de nuestras casas, ¿no? Dentro de nuestra vida personal. Entonces, hay que tener ahí algunas rutinas para poder tener más productividad. Y hablando de este punto del trabajo mezclando con nuestra vida personal, ¿no? Eso es algo que hoy en día es lo que más hay porque estamos en el trabajo, pero nosotros estamos en nuestra casa, estamos con nuestra familia, con las personas con las que vivimos. ¿Cómo podemos, entonces, equilibrar esos dos lados de nuestro día a día? Es un reto. Es un reto, pero sí se puede. Entonces, creo que lo más importante en este caso es establecer límites. Entonces, tener horarios y respetarlos. Claro que eso también tenemos que tener el apoyo de la empresa para que ellos también respeten esos horarios y para que podamos tener más calidad de vida. Perfecto, Raquel. Bueno, muchas gracias aquí por ayudarnos a entender mejor cuáles son los desafíos y cómo podemos encontrar soluciones para el trabajo remoto, ahora que ya estamos trabajando desde casa, ¿no? Bueno, muchas gracias a ti también que te quedaste en este vídeo con nosotros hasta el final. Si aún no estás suscrito en el canal de Aluradam, te invito a suscribirte y que pronto regresaremos con más vídeos.\n"
          ]
        }
      ]
    }
  ]
}